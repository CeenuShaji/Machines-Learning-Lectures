{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 16 Part 1 - Cluster Validity Metrics & Non-Parametric Classification with K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Validity Metrics\n",
    "\n",
    "How would you evaluate clustering results? - **Cluster Validity Indices**\n",
    "    \n",
    "* Cluster validity indices are used for a number of different goals. For example, cluster validity metrics can be used to compare clustering results, try to determine the *correct* number of clusters, try to select the *correct* parameter settings, try to evaluate the appropriateness of the clustering result based on the data only (and not using another result or \"ground truth\" data).\n",
    "    \n",
    "In general, there are three types of **index criteria** to perform cluster validity:\n",
    "\n",
    "1. **Internal criteria.** We evaluate the results of a clustering algorithm in terms of quantities that involve the vectors of the data set themselves. \n",
    "2. **External criteria.** We evaluate the results of a clustering algorithm based on a pre-specified structure, which is imposed on a data set and reflects our intuition about the clustering structure of the data set.\n",
    "3. **Relative criteria.** We evaluate the results of a clustering structure by comparing it to other clustering schemes, resulting by the same algorithm but with different parameter values. In practice, relative criteria are a combination on internal and external criteria.\n",
    "\n",
    "## Internal Criteria \n",
    "\n",
    "As the goal of clustering is to make objects within the same cluster similar and objects in different clusters distinct, internal cluster validity measures are defined by combining compactness and separability.\n",
    "\n",
    "The optimal clustering scheme under the internal criteria index includes:\n",
    "\n",
    "* Compactness (or intra-distance or within-cluster scatter): The members of each cluster should be as close to each other as possible. A common measure of compactness is the variance, which should be minimized.\n",
    "* Separation (or inter-distance or between-cluster scatter): This indicates how distinct two clusters are. It computes the distance between two different clusters. There are three common approaches measuring the distance between two different clusters:\n",
    "    * Single linkage: It measures the distance between the closest members of the clusters. \n",
    "    * Complete linkage: It measures the distance between the most distant members. \n",
    "    * Comparison of centroids: It measures the distance between the centers of the clusters. \n",
    "\n",
    "### Example: Silhouette Index\n",
    "\n",
    "The Silhoute Index is an internal cluster validity index that is used to judge the quality of any clustering solution. \n",
    "\n",
    "Given a set of data points $X=\\{x_1,\\dots,x_N\\}$ and a partition of $X$ (i.e. clustering result). Let's define the following:\n",
    "* $a_i$ is the average distance of the point $x_i$ to all the other points of the cluster in which $x_i$ is assigned to\n",
    "* $b_i$ is the average distance of the point $x_i$ to all the other points of in the other clusters. \n",
    "\n",
    "For every data point $x_i \\in X$, the Silhouette Index is defined as:\n",
    "\n",
    "$$s = \\frac{1}{N} \\sum_{i=1}^N \\frac{b_i-a_i}{\\max(a_i,b_i)}$$\n",
    "\n",
    "* Silhouette index is the average silhouette of all data points and it reflects the compactness and separation of clusters.\n",
    "\n",
    "* The value of silhouette index varies from -1 and 1 and higher indicates better clustering results.\n",
    "\n",
    "There are many other internal cluster validity indices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Criteria\n",
    "\n",
    "External cluster validity indices are used to measure how well a clustering result matches a set of *give* labels. \n",
    "External cluster validity indices can be used to:\n",
    "* compare the clustering results with the *ground truth* (true labels),\n",
    "* compare clustering results between different clustering algorithms to measure how different they are and how stable a particular clustering is on a data set across parameter settings and/or algorithms.\n",
    "\n",
    "### Example: Rand Index\n",
    "\n",
    "The Rand Index is an external cluster validity index that is used to compare clustering results obtained from different parameter settings or algorithms. \n",
    "\n",
    "Given a set of data points $X$ and two partitions (i.e. clustering results) of $X$ to compare. One partition $C=\\{C_1, \\dots,C_k\\}$, that partitions $X$ into $k$ clusters, and another partition $D=\\{D_1,\\dots,D_s\\}$, that partitions $X$ into $s$ clusters. Let's define the following:\n",
    "\n",
    "* $a$ is the number of pairs of elements in $X$ that are in the same subset in $C$ and in the same subset in $D$.\n",
    "* $b$ is the number of pairs of elements in $X$ that are in different subset in $C$ and in different subset in $D$.\n",
    "* $c$ is the number of pairs of elements in $X$ that are in the same subset in $C$ and in different subset in $D$.\n",
    "* $d$ is the number of pairs of elements in $X$ that are in different subset in $C$ and in the same subset in $D$.\n",
    "\n",
    "The Rand Index is defined as:\n",
    "\n",
    "$$r = \\frac{a+b}{a+b+c+d}$$\n",
    "\n",
    "* Intuitively, $a+b$ can be considered as the number of *agreements* between $C$ and $D$, and $c+d$ as the number of *disagreements* between $C$ and $D$.\n",
    "\n",
    "* The value of rand index varies from 0 and 1 and higher indicates higher consistency between partitions $C$ and $D$.\n",
    "\n",
    "There are many other external cluster validity indices!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (or KNN)\n",
    "\n",
    "1. It is a supervised learning algorithm.\n",
    "\n",
    "2. It is a non-parametric classifier\n",
    "    * KNN belongs to a subcategory of nonparametric models that is described as **instance-based learning**. Models based on instance-based learning are characterized by memorizing the training dataset, and lazy learning is a special case of instance-based learning that is associated with no (zero) cost during the learning process.\n",
    "\n",
    "3. It is known as a *lazy learner*. It is called lazy not because of its apparent simplicity, but because it doesn't learn a discriminative function from the training data, but memorizes the training dataset instead.\n",
    "    * Nearest neighbors methods compare a test point to the $K$ nearest training data points and then estimate an output value based on the desired/true output values of the $K$ nearest training points.\n",
    "\n",
    "4. Essentially, there is no \"training\" other than storing the training data points and their desired outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-Code for KNN\n",
    "\n",
    "The KNN algorithm itself is fairly straightforward and can be summarized by the following steps: \n",
    "1. Choose the number of neighbors, $K$, and a distance metric. \n",
    "\n",
    "2. Find the $K$ nearest neighbors of the sample that we want to classify. \n",
    "\n",
    "3. Assign the class label by majority vote.\n",
    "\n",
    "Based on the chosen distance metric, the KNN algorithm finds the $K$ samples in the training dataset that are closest (most similar) to the point that we want to classify. The class label of the new data point is then determined by a majority vote among its $K$ nearest neighbors.\n",
    "\n",
    "* If there are ties, they can be broken randomly or using schemes like applying the label to the closest data point in the neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages & Challenges\n",
    "\n",
    "The main advantage of such a memory-based approach is that the classifier immediately **adapts as we collect new training data**. \n",
    "\n",
    "However, the downside is that the **computational complexity** for classifying new samples grows linearly with the number of samples in the training dataset in the worst-case scenario - unless the dataset has very few dimensions (features) and the algorithm has been implemented using efficient data structures such as **K-D trees**. \n",
    "\n",
    "* For more information about K-D trees, refer to the following work: Friedman, J. H., Bentley, J. L., & Finkel, R. A. (1977). An algorithm for finding best matches in logarithmic expected time. ACM Transactions on Mathematical Software (TOMS), 3(3), 209-226.\n",
    "\n",
    "Furthermore, we can't discard training samples since no training step is involved. Thus, **storage space** can become a challenge if we are working with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "* The *right* choice of $K$ is crucial to find a good balance between overfitting and underfitting. We can find the best value for $K$ using experimental design with **cross-validation**.\n",
    "\n",
    "* We also have to make sure that we choose a **distance metric** that is appropriate for the features in the dataset. Often, a simple Euclidean distance measure is used for real-value samples. However, if we are using a Euclidean distance measure, it is also important to **standardize the data** so that each feature contributes equally to the distance.\n",
    "\n",
    "* It is important to mention that KNN is very susceptible to overfitting due to the **curse of dimensionality**. Intuitively, we can think of even the closest neighbors being too far away in a high-dimensional space to give a good estimate. \n",
    "\n",
    "* We have discussed the concept of **regularization** as one way to avoid overfitting. However, in models where regularization is not applicable (non-parametric), such as decision trees and KNN, we can use feature selection and dimensionality reduction techniques to help us avoid the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Metrics\n",
    "    \n",
    "In order to find the $k$ *nearest-neighbors* in the training data, you need to define a **similarity measure** or a **dissimilarity measure**. The most common dissimilarity measure is Euclidean distrance:\n",
    "\n",
    "* Euclidean distance: $d_E(\\mathbf{x}_1, \\mathbf{x}_2) = \\Vert\\mathbf{x}_1-\\mathbf{x}_2\\Vert_2 = \\sqrt{(\\mathbf{x}_1 - \\mathbf{x}_2)^T(\\mathbf{x}_1 - \\mathbf{x}_2)}$\n",
    "\n",
    "* City-block distance: $d_{CB}(\\mathbf{x}_1,\\mathbf{x}_2) = \\sum_{i=1}^n |\\mathbf{x}_{1i} - \\mathbf{x}_{2i}|$\n",
    "\n",
    "* Mahalanobis distance: $d_M(\\mathbf{x}_1, \\mathbf{x}_2) = \\sqrt{(\\mathbf{x}_1 - \\mathbf{x}_2)^T\\Sigma^{-1}(\\mathbf{x}_1 - \\mathbf{x}_2)}$\n",
    "\n",
    "* Cosine distance: $d_{cos}(\\mathbf{x}_1, \\mathbf{x}_2) = 1 - \\cos(\\angle(x_1,x_2)) = 1 - \\frac{\\mathbf{x}_1^T \\mathbf{x}_2}{\\Vert\\mathbf{x}_1\\Vert_2 \\Vert\\mathbf{x}_2\\Vert_2}$\n",
    "\n",
    "* and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles, make_classification, make_blobs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
    "\n",
    "# figure parameters\n",
    "h = .02  # step size in the mesh\n",
    "figure = plt.figure(figsize=(20, 20))\n",
    "\n",
    "# set up classifiers\n",
    "n_neighbors = 3\n",
    "classifiers = [KNeighborsClassifier(n_neighbors, weights='uniform'), \\\n",
    "               KNeighborsClassifier(n_neighbors, weights='distance')]\n",
    "names = ['k-NN Uniform', 'k-NN Weighted']\n",
    "\n",
    "# Put together Data Sets\n",
    "n_samples = 300\n",
    "X, y = make_classification(n_samples, n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable,\n",
    "            make_blobs(centers=[[-1,-1],[2,1]])]\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 2, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title('Input data',size=20)\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, s=100,\n",
    "               edgecolors='k',label='Training points')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], marker='*', s=100, c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k',label='Test points')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.legend(fontsize=15)\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 2, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "#         Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "        #Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, s=100,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], marker='*', c=y_test, cmap=cm_bright, s=100,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name,size=20)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        \n",
    "        i += 1\n",
    "    # Confusion Matrix\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 2, i)\n",
    "    cm = confusion_matrix(y_test, y_predict, labels=clf.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "    disp.plot(ax=ax)\n",
    "    i += 1    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "1. What happens when there are imbalanced classes?\n",
    "\n",
    "2. Is k-NN sensitive to data scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
