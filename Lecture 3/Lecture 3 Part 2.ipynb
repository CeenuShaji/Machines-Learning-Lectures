{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 Part 2 - Cross-Validation & Performance Measures for Regression Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last period, we introduce one strategy to avoid overfitting: regularization. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Regularization</b> \n",
    "\n",
    "Regularization constrains (or regularizes) the parameter coefficients such that they cannot take a large value. Regularization of the model parameters discourages learning a more complex, as to avoid the risk of overfitting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there other strategies to apply in order to mitigate overfitting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to Avoid Overfitting\n",
    "\n",
    "1. Add more data! - when possible\n",
    "\n",
    "2. Occam's Razor - select a model with lower complexity\n",
    "\n",
    "3. Regularization - constrains/regularizes the coefficients of the model\n",
    "\n",
    "4. Cross-validation - technique for utilizing the training data to fine-tune hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will introduce **cross-validation**. Recall the implementation for the regularized polynomial regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoisySinusoidalData(N, a, b, sigma):\n",
    "    '''Generates N data points in the range [a,b) sampled from a sin(2*pi*x) \n",
    "    with additive zero-mean Gaussian random noise with standard deviation sigma'''\n",
    "    \n",
    "    # N input samples, evenly spaced numbers between [a,b) incrementing by 1/N\n",
    "    x = np.linspace(a,b,N)\n",
    "    \n",
    "    # draw N sampled from a univariate Gaussian distribution with mean 0, sigma standard deviation and N data points\n",
    "    noise = np.random.normal(0,sigma,N)\n",
    "    \n",
    "    # desired values, noisy sinusoidal\n",
    "    t = np.sin(2*np.pi*x) + noise\n",
    "    \n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input samples and desired values\n",
    "N_train = 50 # number of data samples for training\n",
    "N_test = 20 # number of data samples for test\n",
    "\n",
    "a, b = [0,1] # data samples interval\n",
    "\n",
    "sigma_train = 0.4 # standard deviation of the zero-mean Gaussian noise -- training data\n",
    "sigma_test = 0.1 # standard deviation of the zero-mean Gaussian noise -- test data\n",
    "\n",
    "x_train, t_train = NoisySinusoidalData(N_train, a, b, sigma_train) # Training Data - Noisy sinusoidal\n",
    "x_true, t_true = NoisySinusoidalData(N_train, a, b, 0) # True Sinusoidal - in practice, we don't have the true function\n",
    "x_test, t_test = NoisySinusoidalData(N_test, a, b, sigma_test) # Test Data - Noisy sinusoidal\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(x_train, t_train, c='b', linewidths=3, label = 'Training Data')\n",
    "plt.plot(x_true, t_true, 'g', linewidth=4, label = 'True Mapper')\n",
    "plt.plot(x_test, t_test, 'r^', label = 'Test Data')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Data Samples, $x$',size=15)\n",
    "plt.ylabel('Target Labels, $t$',size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolynomialRegression(x,t,M):\n",
    "    '''Fit a polynomial of order M to the data input data x and desire values t'''\n",
    "    # Compute feature matrix X with polynomial features\n",
    "    X = np.array([x**m for m in range(M+1)]).T #computes the phi(x) = [x^0, x^1, ...., x^M]\n",
    "    # Compute the solution for the parameters w\n",
    "    w = np.linalg.inv(X.T@X)@X.T@t # Optimal set of parameters w\n",
    "    # Compute model prediction\n",
    "    y = X@w\n",
    "    return w, y\n",
    "\n",
    "def PolynomialRegression_reg(x,t,M,lam):\n",
    "    # Compute feature matrix X with polynomial features\n",
    "    X = np.array([x**m for m in range(M+1)]).T\n",
    "    # Compute the solution for the parameters w\n",
    "    w = np.linalg.inv(X.T@X + lam*np.eye(M+1))@X.T@t\n",
    "    # Compute model prediction\n",
    "    y = X@w\n",
    "    return w, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "lam = 0.001\n",
    "\n",
    "w, y, = PolynomialRegression(x_train,t_train,M) \n",
    "wreg, yreg = PolynomialRegression_reg(x_train,t_train,M,lam) \n",
    "\n",
    "fig=plt.figure(figsize=(10,6))\n",
    "plt.scatter(x_train,t_train, label='Training Data')\n",
    "plt.plot(x_train,y,'r', label = 'Polynomial Regression')\n",
    "plt.plot(x_train,yreg, 'b',label = 'Polynomial Regression w/ Regularizer')\n",
    "plt.plot(x_true,t_true,'--g', label = 'True Function')\n",
    "plt.legend(bbox_to_anchor=(1.5, 1),fontsize=12,ncol=1)\n",
    "plt.xlabel('Data Samples, $x$', fontsize=20)\n",
    "plt.ylabel('Desired Labels, $t$', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolynomialRegression_test(x,M,w):\n",
    "    # Feature matrix for test set\n",
    "    X = np.array([x**m for m in range(M+1)]).T\n",
    "    \n",
    "    # Prediction for test set\n",
    "    y = X@w\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for test set using non-regularized model\n",
    "y_test = PolynomialRegression_test(x_test, M, w)\n",
    "\n",
    "# Prediction for test set using regularized model\n",
    "y_test_reg = PolynomialRegression_test(x_test, M, wreg)\n",
    "\n",
    "# Plotting\n",
    "fig=plt.figure(figsize=(10,6))\n",
    "plt.plot(x_true, t_true, '--g', label = 'True Function')\n",
    "plt.plot(x_test, t_test, 'r^', label = 'Test Data')\n",
    "plt.plot(x_test,y_test,'r', label = 'Polynomial Regression')\n",
    "plt.plot(x_test,y_test_reg, 'b',label = 'Polynomial Regression w/ Regularizer')\n",
    "plt.legend(bbox_to_anchor=(1.5, 1),fontsize=12,ncol=1)\n",
    "plt.xlabel('Test Samples, $x$', fontsize=20)\n",
    "plt.ylabel('Desired Labels, $t$', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning the Hyperparameters\n",
    "\n",
    "The hyperparameters of ridge regression are the model order $M$ and the regularizer coefficient $\\lambda$.\n",
    "\n",
    "How would you choose which value to use? -- Cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "The goal of **cross-validation**, or CV, is to test the model's ability to predict new data that was not used in estimating the model, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset).\n",
    "\n",
    "Cross-validation allows us to determine the values for the hyperparameter that provide the most **generalization**. Cross-validation mitigates the occurrrence of overfitting, but it does not eliminate it entirely.\n",
    "\n",
    "* Reading: [Sections 19.1-19.6](https://ufl.instructure.com/courses/455013/external_tools/412362?display=borderless) from the Alpaydin textbook and [Section 5.3 Hyperparameters and Model Validation](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html) from the \"Python Data Science Handbook\" textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measures\n",
    "\n",
    "In order to determine if the model is able to **generalize** to a **validation set**, we need to determine a **performance measure**.\n",
    "\n",
    "Which _quantitative_ measure would you use to compare model performances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Measures\n",
    "\n",
    "Error measures are always a good start for **regression** tasks. Some examples include:\n",
    "\n",
    "* **Mean Squared Error (MSE)** - best when the data does not have outliers. The MSE will penalize outliers heavily.\n",
    "\n",
    "* **Mean Absolute Error (MAE)** - best when you suspect data has outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual error for Training data for polynomial regression without and with regularizer\n",
    "error_train = t_train - y \n",
    "error_train_reg = t_train - yreg \n",
    "\n",
    "# Residual error for Test data for polynomial regression without and with regularizer\n",
    "error_test = t_test - y_test\n",
    "error_test_reg = t_test - y_test_reg\n",
    "\n",
    "# Error Measures\n",
    "print('Mean Squared Error \\n')\n",
    "print('Training Set')\n",
    "print('Without regularizer: ', np.mean(error_train**2))\n",
    "print('With regularizer: ', np.mean(error_train_reg**2),'\\n')\n",
    "print('Test Set')\n",
    "print('Without regularizer: ', np.mean(error_test**2))\n",
    "print('With regularizer: ', np.mean(error_test_reg**2),'\\n')\n",
    "print('----------------------------------------------------------------')\n",
    "print('Mean Absolute Error \\n')\n",
    "print('Training Set')\n",
    "print('Without regularizer: ', np.mean(np.abs(error_train)))\n",
    "print('With regularizer: ', np.mean(np.abs(error_train_reg)),'\\n')\n",
    "print('Test Set')\n",
    "print('Without regularizer: ', np.mean(np.abs(error_test)))\n",
    "print('With regularizer: ', np.mean(np.abs(error_test_reg)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other error-based measures can be considered, e.g., normalized mean squared error (NMSE), normalized mean absolute error (NMAE), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Q Plot\n",
    "\n",
    "We can also use the **Quantile-Quantile (Q-Q)** plot to assess qualitative measures of goodness-of-fit.\n",
    "\n",
    "* The Q-Q plot help us assess if a set of data plausibly came from some theoretical distribution such as a Normal or exponential, or if two sets of samples were drawn from the same distribution. For example, if we run a statistical analysis that assumes our dependent variable is Normally distributed, we can use a Normal Q-Q plot to check that assumption. It's just a visual check, not an air-tight proof, so it is somewhat subjective. But it allows us to see at-a-glance if our assumption is plausible, and if not, how the assumption is violated and what data points contribute to the violation.\n",
    "\n",
    "* What are *quantiles*? These are often referred to as *percentiles*. These are points in your data below which a certain proportion of your data fall which are captured in the Cumulative Distribution Function (CDF) of a random variable. For example, imagine the classic bell-curve standard Normal distribution with a mean of 0. The 0.5 quantile, or 50th percentile, is 0. Half the data lie below 0. That's the peak of the hump in the curve. The 0.95 quantile, or 95th percentile, is about 1.64. 95 percent of the data lie below 1.64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.linspace(min(t_test),max(t_test),100)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1); plt.scatter(np.sort(t_test), np.sort(y_test))\n",
    "#NOTE: the true values and predictions are sorted because we are \n",
    "#inferring quantiles of the underlying probabilistic model from data samples\n",
    "plt.plot(base,base,'r')\n",
    "plt.xlabel('Target Quantiles', size=15)\n",
    "plt.ylabel('Estimated Quantiles', size=15)\n",
    "plt.title('Polynomial Model without regularizer',size=20)\n",
    "\n",
    "plt.subplot(1,2,2); plt.scatter(np.sort(t_test), np.sort(y_test_reg))\n",
    "#NOTE: the true values and predictions are sorted because we are \n",
    "#inferring quantiles of the underlying probabilistic model from data samples\n",
    "plt.plot(base,base,'r')\n",
    "plt.xlabel('Target Quantiles', size=15)\n",
    "plt.ylabel('Estimated Quantiles', size=15)\n",
    "plt.title('Polynomial Model with regularizer',size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then take a summative **quantitative** measure, namely the **coefficient of determination**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "print('Polynomial Regression Without Regularization - Test Set')\n",
    "m, b, r, p, _ = stats.linregress(np.sort(t_test), np.sort(y_test))\n",
    "print('Coefficient of Determination: ',r**2)\n",
    "print('Slope: ',m)\n",
    "print('Intercept: ',b)\n",
    "print('p-value: ', p)\n",
    "print('-------------------')\n",
    "print('Polynomial Regression With Regularization - Test Set')\n",
    "m, b, r, p, _ = stats.linregress(np.sort(t_test), np.sort(y_test_reg))\n",
    "print('Coefficient of Determination: ',r**2)\n",
    "print('Slope: ',m)\n",
    "print('Intercept: ',b)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most applications, we want a model with a coefficient of determination $r^2\\geq99\\%$.\n",
    "\n",
    "In this example, the exponential performs better than the polynomial model in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Performance Measures\n",
    "\n",
    "Performance of an algorithm can be determined using a variety of statistical goodness-of-fit measures. \n",
    "\n",
    "* For regression tasks this includes error-based measurements, hypothesis tests, Q-Q plots.\n",
    "* For classification tasks this includes error rate, accuracy, ROC curves, performance-recall curves.\n",
    "\n",
    "But it can also be in terms of:\n",
    "1. Risk,\n",
    "2. Training time,\n",
    "3. Training storage/memory,\n",
    "4. Testing time,\n",
    "5. Testing storage/memory,\n",
    "6. Interpretability, namely, whether the method allows knowledge extraction which can be checked and validated by experts, and\n",
    "7. computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coming back to Cross-Validation\n",
    "\n",
    "Let's consider the **MSE** as our performance measure. There are different strategies for implementing cross-validation:\n",
    "\n",
    "1. k-fold cross-validation\n",
    "2. Leave-One-Out cross-validation\n",
    "3. Stratified cross-validation\n",
    "4. $k\\times 2$ cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to make sure that classes are represented in the right proportions when subsets of data are held out, not to disturb the class prior probabilities; this is called **stratiﬁcation**. If a class has 20 percent examples in the whole dataset, in all samples drawn from the dataset, it should also have approximately 20 percent examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## $1\\times 2$ cross-validation\n",
    "\n",
    "Let's consider the case, where we only have a single validation set which resulted from splitting the training data into a training set and a validation set with splitting rations 70% and 30% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_validation, t_train2, t_validation = train_test_split(x_train, \n",
    "                                                                  t_train, \n",
    "                                                                  test_size=0.3,\n",
    "                                                                 shuffle=True)\n",
    "\n",
    "x_train2.shape, x_validation.shape, t_train2.shape, t_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now vary the values for $M$ and estimate the associated coefficients $\\mathbf{w}$ using the training set. Then, let's evaluate performance measure (e.g. MSE) in both training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_vals = range(1,12)\n",
    "\n",
    "MSE_train = []\n",
    "MSE_val = []\n",
    "for M in M_vals:\n",
    "    \n",
    "    # Train the model (without regularization for simplicity of illustration)\n",
    "    \n",
    "    \n",
    "    # Make predictions for the training and validation sets\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Performance Measure\n",
    "    \n",
    "    \n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(M_vals, MSE_train, '-og',label='Training Set')\n",
    "plt.plot(M_vals, MSE_val, '-or',label='Validation Set')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Model order, $M$', size=15)\n",
    "plt.ylabel('Performance Measure, MSE', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which model order would you choose? Why?\n",
    "\n",
    "The phenomenon we observe here is known as the **bias-variance trade-off** (more next lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## K-Fold Cross-Validation\n",
    "\n",
    "The technique of k-fold cross-validation, illustrated below for the case of $k=4$, involves taking the available data and partitioning it into $k$ groups (in the simplest case these are of equal size). Then $k-1$ of the groups are used to train a set of models that are then evaluated on the remaining group. This procedure is then repeated for all $k$ possible choices for the held-out group, indicated in the picture below by the red blocks, and the performance scores from the runs are then averaged.\n",
    "\n",
    "$K$ is typically 10 or 30. As $K$ increases, the percentage of training instances increases and we get more robust estimators, but the validation set becomes smaller. Furthermore, there is the cost of training the classiﬁer $K$ times, which increases as $K$ is increased. As $N$ increases, $K$ can be smaller; if $N$ is small, $K$ should be large to allow large enough training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('figures/Kfold CV.png',width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** find the best value for the **hyperparameters** $M$ (model order) and $\\lambda$ (regularization trade-off parameter).\n",
    "\n",
    "Let's use **4-fold cross-validation** on this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training feature matrix into training and validation sets\n",
    "\n",
    "f=1\n",
    "for train_index, validation_index in kf.split(x_train):\n",
    "    print('Fold ', f)\n",
    "    print('The training set has ', train_index.shape[0],' samples')\n",
    "    print('Their index locations are: ', train_index)\n",
    "    print('The validation set has ', validation_index.shape[0],' samples')\n",
    "    print('Their index locations are: ', validation_index,'\\n\\n')\n",
    "    f+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set of values for lambda to explore\n",
    "M_vals = range(1,21)\n",
    "lam_vals= np.arange(0.1,1.1,0.1)\n",
    "\n",
    "for M in M_vals:\n",
    "    for lam in lam_vals:\n",
    "        \n",
    "        print('M Value = ',M)\n",
    "        print('Lambda Value = ',lam)\n",
    "        \n",
    "        # For each training/validation split\n",
    "        f=1\n",
    "        \n",
    "        #initialize performance measures\n",
    "        MSE_train_avg,MSE_val_avg = 0, 0\n",
    "        \n",
    "        for train_index, validation_index in kf.split(x_train):\n",
    "            print('\\nFold ',f)\n",
    "            \n",
    "            # Select training set using the indices found from kf.split\n",
    "            x_train2, x_validation = x_train[train_index], x_train[validation_index]\n",
    "            \n",
    "            # Select validation set using the indices found from kf.split\n",
    "            t_train2, t_validation = t_train[train_index], t_train[validation_index]\n",
    "            \n",
    "            # Training model with training set\n",
    "            w, y_train = PolynomialRegression_reg(x_train2, t_train2, M, lam)\n",
    "            \n",
    "            # Evaluate trained model in validation set\n",
    "            y_val = PolynomialRegression_test(x_validation, M, w)\n",
    "            \n",
    "            # Performance Measure\n",
    "            MSE_train = np.mean((t_train2-y_train)**2)\n",
    "            MSE_val   = np.mean((t_validation-y_val)**2)\n",
    "            \n",
    "            # Average performance measure\n",
    "            MSE_train_avg = MSE_train_avg+MSE_train\n",
    "            MSE_val_avg = MSE_val_avg+MSE_val\n",
    "            print('MSE Training = ', MSE_train)\n",
    "            print('MSE Validation = ', MSE_val)\n",
    "            f+=1\n",
    "            \n",
    "        print('\\nAverage Performance in Training = ', MSE_train_avg/k)\n",
    "        print('Average Performance in Validation = ', MSE_val_avg/k)\n",
    "        print('-----------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "* We select the set of hyperparameters $\\{M,\\lambda\\}$ with the best performance score (e.g. smallest MSE or largest $r^2$).\n",
    "\n",
    "* If the value of the hyperparameter falls at the edge of provided range of values, it is appropriate to expand the range of values for further exploration.\n",
    "\n",
    "* Other performance measures can be used, for example, the coefficient of determination of the Q-Q plot for regression tasks, or accuracy score for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Leave-One-Out Cross-Validation\n",
    "\n",
    "One extreme case of cross-validation is the **leave-one-out** where given a dataset of $N$ instances, only one instance is left out as the validation set (instance) and training uses the $N − 1$ instances. We then get $N$ separate pairs by leaving out a different instance at each iteration. This is typically used in applications such as medical diagnosis, where labeled data is hard to ﬁnd. Leave-one-out **does not permit stratiﬁcation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
