{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11 - Midterm Exam Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Exam: <font color=blue>Monday, October 10</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Section|\tDate |\tTime |\tLocation |\tModality |\n",
    "| -- | -- | --- | ---| ---|\n",
    "| EEL5840 On-campus |\tMonday, October 10 |\t7:20 PM - 9:20 PM |\tWEIM 1064 |\tin-person |\n",
    "| EEL5840 EDGE/Online |\tMonday, October 10 |\twithin 24 hours |\tHonorlock |\tonline |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDGE/Online Exams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Online exams will be proctored with Honolorck. Find more information here: https://distance.ufl.edu/proctoring/\n",
    "\n",
    "* Install [**CamScanner app**](https://www.camscanner.com/) on your phone.\n",
    "\n",
    "* **Bring 6 clean sheets to write your answers.** \n",
    "\n",
    "* Show to the camera all of your clean paper.\n",
    "\n",
    "* You may call me at (352) 392-6502 if you have any questions. (I do not receive texts in this number.)\n",
    "\n",
    "* Once the 2 hours have elapsed, please use the additional 10 minutes to scan your handwritten solutions (including your formula sheet) and upload it to Canvas as a single PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam Details\n",
    "\n",
    "* **Coverage**: lectures 1-11 (modules 1-5)\n",
    "\n",
    "* **Practice exam**: available in the [Assignment-Solutions repo](https://github.com/UF-EEL5840-F22/Assignment-Solutions)\n",
    "    * Solutions have been posted\n",
    "    \n",
    "* **Allowed Material**\n",
    "    * 1-page letter-sized of formulas (front and back, handwritten or typed). **Formulas only!**. **Do not include** pseudo-code, solved exercises, lecture derivations or any written definitions.\n",
    "    * Scientific calculator\n",
    "\n",
    "* **Total time**: 2 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm Exam Coverage\n",
    "\n",
    "The midterm exam will cover all materials from Lecture 1-10 + today's midterm review. These include:\n",
    "\n",
    "1. **Introduction to Machine Learning <font color=blue>(Lectures 1-2)</font>**\n",
    "    * Definition of Machine Learning, Artificial Intelligence and Deep Learning\n",
    "    * Types of learning in Machine Learning\n",
    "    * Supervised Learning diagram\n",
    "    * (Linear) Regression\n",
    "    * Performance Metrics for regression: error metrics, Q-Q plot\n",
    "    \n",
    "2. **Experimental Design and Analysis <font color=blue>(Lectures 3-5)</font>**\n",
    "    * Feature representation: polynomial basis function, radial basis function, etc. \n",
    "        * Basis functions in general\n",
    "    * Model selection\n",
    "    * Occam's Razor\n",
    "    * Generalization\n",
    "    * Regularization: ridge and lasso\n",
    "    * Cross-Validation\n",
    "    * The No Free Lunch Theorem\n",
    "    * The Bias-Variance Trade-Off\n",
    "    * Experimental Design\n",
    "    * Hyperparameters tuning\n",
    "    * The Curse of Dimensionality\n",
    "    \n",
    "3. **Bayesian Learning <font color=blue>(Lectures 6-8)</font>**\n",
    "    * Frequentist vs Bayesian statistics\n",
    "    * Bayesian interpretation of Regression Least Squares Objective Function \n",
    "    * Maximum Likelihood Estimation (MLE)\n",
    "    * Maximum A Posteriori (MAP)\n",
    "    * Bayesian Prior Equivalence\n",
    "    * Conjugate Priors, Online update\n",
    "    \n",
    "4. **Generative Classification <font color=blue>(Lectures 9-10)</font>**\n",
    "    * Distinction between classification and regression\n",
    "    * Probabilistic Generative Models\n",
    "    * Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to prepare for exam\n",
    "\n",
    "**This is a suggestion only.**\n",
    "\n",
    "1. Review/read all Notebooks.\n",
    "\n",
    "2. Create your formula sheet. **Do not include written descriptions, pseudo-code or solved exercises (including derivations).** \n",
    "\n",
    "3. Review/redo exercises from HW1. \n",
    "\n",
    "4. Review/redo exercises from SA1 and SA2.\n",
    "\n",
    "5. Review discussion boards 1 and 2.\n",
    "\n",
    "6. Solve practice exam provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Discussion Board Questions](https://ufl.instructure.com/courses/464118/discussion_topics/3625863)\n",
    "\n",
    "Thank you for posting your questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post 1 & Post 7\n",
    "\n",
    "*How do we determine the update function for alpha and beta for different distributions?* - D. Lentini\n",
    "\n",
    "*Please go through step by step the MLE/MAP derivations* - T. Christensen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider [exercise 6](https://github.com/UF-EEL5840-F22/Assignment-Solutions/blob/main/Midterm%20-%20review%20from%20Summer%202022/Midterm_Exam_EEL5840_Summer_2022.pdf) from the practice midterm.\n",
    "\n",
    "> Suppose you have a training set with $N$ data points $\\{x_i\\}_{i=1}^N$, where $x_i\\in\\mathbb{Z}_0^+$ (set of nonnegative integers - $0,1,2,3,\\dots$). Assume the samples are independent and identically distributed (i.i.d.), and each sample is drawn from a Geometric random variable with probability mass function:\n",
    "\\begin{align*}\n",
    "    P(x|\\rho) = \\rho(1-\\rho)^x\n",
    "\\end{align*}\n",
    "\n",
    "> Moreover, consider the Beta density function as the prior probability on the success probability, $\\rho$,\n",
    "\\begin{align*}\n",
    "    P(\\rho|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\rho^{\\alpha-1}(1-\\rho)^{\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "> 1. Derive the maximum likelihood estimate (MLE) for the rate parameter $\\rho$. Show your work.\n",
    "> 2. Derive the maximum a posteriori (MAP) estimate for the rate parameter $\\rho$. show your work.\n",
    "> 3. Is the Beta distribution a conjugate prior for the success probability, $\\rho$, of the Geometric distribution? Why or why not?\n",
    "> 4. Suppose you would like to update the Beta prior distribution and the MAP point estimation in an online fashion, as you obtain more data. Write the pseudo-code for the online update of the prior parameters. In your answer, specify the new values for the parameters of the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post 2\n",
    "\n",
    "*In which case should we apply .fit, .transform and .fit_transform and what are the differences between those methods? Thanks!* - J. Ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the crab dataset from SA2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"crab.txt\", delimiter=\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning the data into training and test sets\n",
    "\n",
    "X_train = data.iloc[:140,1:].to_numpy()\n",
    "t_train = data.iloc[:140,0].to_numpy()\n",
    "\n",
    "X_test = data.iloc[140:,1:].to_numpy()\n",
    "t_test = data.iloc[140:,0].to_numpy()\n",
    "\n",
    "X_train.shape, X_test.shape, t_train.shape, t_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# This pipeline will apply Standardization to all numerical attributes \n",
    "# The attributes that are one-hot/interger-encoded (such as gender) will remain as is\n",
    "\n",
    "scaling_pipeline = ColumnTransformer([('num_attribs', StandardScaler(), list(range(5)))],\n",
    "                                    remainder='passthrough')\n",
    "scaling_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_pipeline.fit(X_train)\n",
    "\n",
    "# The fit() method learns the necessary parameters of the pipeline.\n",
    "# Since this pipeline includes preprocessing scalars, it will learn the mean and std for each attriute\n",
    "# If it were a classifier/regression, it will train all the parameters associated with that classifier/regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# You can access the trained attributes of this object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The method transform() will apply these parameters to the input data.\n",
    "# In this case, each feature will be scale with (f-mu)/std\n",
    "\n",
    "X_train_scaled = scaling_pipeline.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaling_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The method fit_transform() trains the parameters and applies them to the input data\n",
    "# This method should only be used for the training set\n",
    "\n",
    "X_train_scaled_2 = scaling_pipeline.fit_transform(X_train)\n",
    "X_test_scaled_2 = scaling_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post 3\n",
    "\n",
    "*When should we and when should we not normalize data before modeling?* - S. Kucharski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always normalize data! \n",
    "\n",
    "This is especially important when working with algorithms that make use of distances and other similarities measures for finding patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post 4 & Post 8\n",
    "\n",
    "*Could you please go through the Bayesian interpretation? Like the theory, the advantage and when is the appropriate time to use it.* - A. Jiang\n",
    "\n",
    "*In class, you mentioned how if there is a right skew, you would want to use a Laplacian. Can you expand on what right skew means?* - B. Emison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correction: the Laplacian distribution has skewness 0. Meaning that it is symmetric wrt to its mean. In other words, the 3rd central moment of the Laplacian RV $X$ is 0, i.e. $E[(X-E[X])^3]=0$.\n",
    "\n",
    "* The Exponential and Gamma RVs are examples of RVs with positive skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "alpha=2\n",
    "beta=2\n",
    "X = stats.gamma(a=alpha,scale=1/beta)\n",
    "xline = np.linspace(-1,5,1000)\n",
    "\n",
    "plt.plot(xline, X.pdf(xline));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post 5 & Post 6\n",
    "\n",
    "*If there is time during the review session can we review mixture models since lecture 10 was cut short last week? Or at least can you review what we will be expected to know for the exam regarding that topic?* - S. Kucharski\n",
    "\n",
    "*We didn't have enough time in Lecture 9 and 10 to go deep into \"Mixture Models\", \"Gaussian Mixture Models (GMM)\" and \"the Expectation-Maximization (EM) Algorithm\". I see them in the practice questions. Are these part of the mid-term? If so, can we review the key concepts in terms of what we are expected to know? Thanks.* - Z. Zong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture Models (including Gaussian Mixture Models) and the EM algorithm will not be assessed in the midterm exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post 9\n",
    "\n",
    "*After performing k-fold cross validation in HW1 P2, I noticed it was more difficult than I thought to select the best regularizer hyperparameter that repeatably minimized the error in the validation set. Could you go over some strategies/approaches we should take to interpret the results of cross validation and select the best hyperparameter set, specifically regarding the regularizer hyperparameter? There are a lot of really good examples of what an overfit model looks like during cross validation of the model order, but less so for regularizer terms. How big is too big for a regularizer?* - C. Charters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
